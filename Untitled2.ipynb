{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUexvQusuuQZcnsuiOs5Ey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nanabewbew/co2-emissions/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "WtCBW0-3hHx4",
        "outputId": "55666134-504f-4e8d-e380-1d207a68240b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Fuel.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c105a507d1f8>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fuel.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m\"FUELCONSUMPTION_CITY\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"FUELCONSUMPTION_HWY\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FUELCONSUMPTION_COMB_MPG\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FUELCONSUMPTION_COMB\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#features{numeric}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"CO2EMISSIONS\"\u001b[0m \u001b[0;31m#target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Fuel.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def linear_regression(X, y, learning_rate, num_iters, tolerance=1e-3):\n",
        "    m, n = X.shape\n",
        "    weights = np.random.rand(n)  # Random initialization\n",
        "    bias = 0\n",
        "    prev_weights = weights.copy()\n",
        "\n",
        "    for _ in range(num_iters):\n",
        "        # Calculate predictions\n",
        "        predictions = np.dot(X, weights) + bias\n",
        "\n",
        "        # Calculate errors\n",
        "        errors = predictions - y\n",
        "\n",
        "        # Update weights and bias\n",
        "        weights -= learning_rate * np.dot(X.T, errors) / m\n",
        "        bias -= learning_rate * np.mean(errors)\n",
        "\n",
        "        # Check for convergence\n",
        "        if np.linalg.norm(weights - prev_weights) < tolerance:\n",
        "            break\n",
        "\n",
        "        # Update previous weights\n",
        "        prev_weights = weights.copy()\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# Load data\n",
        "np.random.seed(42)\n",
        "df = pd.read_csv(\"Fuel.csv\")\n",
        "features = [ \"FUELCONSUMPTION_CITY\",\"FUELCONSUMPTION_HWY\", \"FUELCONSUMPTION_COMB_MPG\", \"FUELCONSUMPTION_COMB\"] #features{numeric}\n",
        "target = \"CO2EMISSIONS\" #target\n",
        "df.info()\n",
        "df.describe()\n",
        "from pandas.plotting import scatter_matrix\n",
        "attributes = [\"FUELCONSUMPTION_CITY\",\"FUELCONSUMPTION_HWY\",\"FUELCONSUMPTION_COMB\",\"FUELCONSUMPTION_COMB_MPG\",\"CO2EMISSIONS\"]\n",
        "scatter_matrix(df[attributes],figsize = (12,8))\n",
        "df.plot(kind=\"scatter\",x=\"FUELCONSUMPTION_COMB\", y=\"CO2EMISSIONS\",alpha=0.8)\n",
        "df.plot(kind=\"scatter\",x=\"FUELCONSUMPTION_COMB_MPG\", y=\"CO2EMISSIONS\",alpha=0.8)\n",
        "df.plot(kind=\"scatter\",x=\"FUELCONSUMPTION_CITY\", y=\"CO2EMISSIONS\",alpha=0.8)\n",
        "df.plot(kind=\"scatter\",x=\"FUELCONSUMPTION_HWY\", y=\"CO2EMISSIONS\",alpha=0.8)\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "import matplotlib.pyplot as plt\n",
        "df.hist(bins=50, figsize=(20,15))\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "learning_rate = 0.01\n",
        "num_iters = 1000\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return np.mean(np.square(y_true - y_pred))\n",
        "\n",
        "def r_squared(y_true, y_pred):\n",
        "    total_variance = np.var(y_true)\n",
        "    explained_variance = np.var(y_true - y_pred)\n",
        "    return 1 - explained_variance / total_variance\n",
        "#model training\n",
        "weights, bias = linear_regression(X_train, y_train, learning_rate=0.001, num_iters=1000)\n",
        "y_pred = np.dot(X_test, weights) + bias #predictions\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r_squared(y_test, y_pred)\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "# test model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_sklearn = model.predict(X_test)\n",
        "mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
        "rmse_sklearn = np.sqrt(mse_sklearn)\n",
        "r2_sklearn = r_squared(y_test, y_pred_sklearn)\n",
        "\n",
        "print(\"\\nSklearn Model:\")\n",
        "print(f\"MSE: {mse_sklearn:.4f}\")\n",
        "print(f\"RMSE: {rmse_sklearn:.4f}\")\n",
        "print(f\"R-squared: {r2_sklearn:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''import setuptools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import impute\n",
        "#from sklearn.model_selection import StratifiedShuffleSplit\n",
        "np.random.seed(42)\n",
        "df = pd.read_csv(\"Fuel.csv\")\n",
        "df.head()\n",
        "df.info()\n",
        "df.describe()\n",
        "import matplotlib.pyplot as plt\n",
        "df.hist(bins=50, figsize=(20,15))\n",
        "def split_train_test(data, test_ratio):\n",
        "    shuffled = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data)*test_ratio)\n",
        "    test_indices = shuffled[:test_set_size]\n",
        "    train_indices = shuffled[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]\n",
        "train_set, test_set = split_train_test(df, 0.2)\n",
        "print(f\"rows in train set: {len(train_set)}\\n rows in test set: {len(test_set)}\\n\" )\n",
        "#corr_matrix = df.corr()\n",
        "#corr_matrix['CO2EMISSIONS'].sort_values(ascendinng=False)\n",
        "from pandas.plotting import scatter_matrix\n",
        "attributes = [\"FUELCONSUMPTION_CITY\",\"FUELCONSUMPTION_HWY\",\"FUELCONSUMPTION_COMB\",\"FUELCONSUMPTION_COMB_MPG\",\"CO2EMISSIONS\"]\n",
        "scatter_matrix(df[attributes],figsize = (12,8))\n",
        "#df.plot(kind=\"scatter\",x=\"FUELCONSUMPTION_COMB\", y=\"CO2EMISSIONS\",alpha=0.8)\n",
        "#df.plot(kind=\"scatter\",x=\"FUELCONSUMPTION_COMB_MPG\", y=\"CO2EMISSIONS\",alpha=0.8)\n",
        "#df.plot(kind=\"scatter\",x=\"FUELCONSUMPTION_CITY\", y=\"CO2EMISSIONS\",alpha=0.8)\n",
        "#df.plot(kind=\"scatter\",x=\"FUELCONSUMPTION_HWY\", y=\"CO2EMISSIONS\",alpha=0.8)\n",
        "df = train_set.drop(\"CO2EMISSIONS\",axis=1)\n",
        "df_labels = train_set[\"CO2EMISSIONS\"].copy()\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "#from sklearn.preprocessing import ColumnTransformer\n",
        "my_pipeline = Pipeline([('imputer',SimpleImputer(strategy=\"median\")),('std_scaler',StandardScaler())])\n",
        "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "#categorical_transformer = Pipeline(steps=[('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "#preprocessor = ColumnTransformer(\n",
        " # transformers=[\n",
        "       # ('num', numeric_transformer, ['MODELYEAR','FUELCONSUMPTION_CITY','CYLINDERS', 'ENGINESIZE','FUELCONSUMPTION_HWY','FUELCONSUMPTION_COMB_MPG', 'FUELCONSUMPTION_COMB']),\n",
        "       # ('cat', categorical_transformer, ['MAKE','MODEL','VEHICLECLASS','TRANSMISSION','FUELTYPE'])\n",
        "    #])\n",
        "\n",
        "#my_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "df_num_tr = my_pipeline.fit_transform(df)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "#from sklearn.tree import DecisionTreeRegressor\n",
        "model = LinearRegression()\n",
        "#model = DecisionTreeRegressor()\n",
        "model.fit(df_num_tr,df_labels)\n",
        "LinearRegression(copy_X=True,fit_intercept=True,n_jobs=None,normalise=False)\n",
        "some_data = df.iloc[:5]\n",
        "some_labels = df_labels.iloc[:5]\n",
        "prepared_data = my_pipeline.transform(some_data)\n",
        "model.predict(prepared_data)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "df_predictions = model.predict()\n",
        "lin_mse = mean_squared_error(df_labels,df_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores=cross_val_score(model,df_num_tr,df_labels,scoring=\"neg_mean_squared_error\")\n",
        "rmse_scores=np.sqrt(-scores)\n",
        "def print_scores(scores):\n",
        "    print(\"Scores\",scores)\n",
        "    print(\"Mean:\",scores.mean())\n",
        "    print(\"Standard deviation:\",scores.std())\n",
        "#saving the model\n",
        "from joblib import dump, load\n",
        "dump(model, 'Untitled-1.joblib')\n",
        "#testing the model\n",
        "X_test = test_set.drop(\"CO2EMISSIONS\",axis=1)\n",
        "Y_test = test_set[\"CO2EMISSIONS\"].copy()\n",
        "X_test_prepared = my_pipeline.transform(X_test)\n",
        "final_predictions = model.predict(X_test_prepared)\n",
        "final_mse = mean_squared_error(Y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(final_predictions, list(Y_test))\n",
        "'''\"import pandas as pd.py\""
      ]
    }
  ]
}